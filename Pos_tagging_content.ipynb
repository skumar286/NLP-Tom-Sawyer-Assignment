{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part of Speech(POS) Tagging or word-category disambiguation : The process of classifying words into their parts\n",
    "### of speech and labeling them accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirement: nltk package,scikit-learn\n",
    "# word_tokenize: NLTK tokenizer tokenizes a sentence into words and punctuation\n",
    "# pos_tag : Tagging is done for certain words from pretrained NLTK model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('They', 'PRP'),\n",
       " (\"'d\", 'MD'),\n",
       " ('love', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('move', 'VB'),\n",
       " ('house', 'NN'),\n",
       " (';', ':'),\n",
       " ('it', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('just', 'RB'),\n",
       " ('so', 'RB'),\n",
       " ('difficult', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('sell', 'VB'),\n",
       " ('right', 'RB'),\n",
       " ('now', 'RB'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize,pos_tag\n",
    "text=word_tokenize(\"They'd love to move house; it's just so difficult to sell right now.\")\n",
    "pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n"
     ]
    }
   ],
   "source": [
    "# The tag set depends on the corpus that was used to train the tagger.\n",
    "# The default tagger of nltk.pos_tag() uses the Penn Treebank Tag Set.\n",
    "# help.upenn_tagset('tag'): Query documenation for each tag from NLTK library.\n",
    "nltk.help.upenn_tagset('VB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('house', 'NN')\n",
      "house\n",
      "NN\n"
     ]
    }
   ],
   "source": [
    "# tagged token is represented using a tuple consisting of the token and the tag.\n",
    "# standard string representation of a tagged token can be represented using the function str2tuple() to tuple.\n",
    "tagged_token = nltk.tag.str2tuple('house/NN')\n",
    "print(tagged_token)\n",
    "print(tagged_token[0])\n",
    "print(tagged_token[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading Tagged Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'), ('Fulton', 'NP-TL'), ...]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading Brown Corpus: word and their corresponding tags are represented using slash. Eg.\n",
    "# Jury/nn-tl said/vbd Friday/nr an/at investigation/nn\n",
    "nltk.corpus.brown.tagged_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training own POS Tagger using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Picking Corpus for training POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n",
      "Tagged sentences:  3914\n",
      "Tagged words: 100676\n"
     ]
    }
   ],
   "source": [
    "tagged_sentences = nltk.corpus.treebank.tagged_sents()\n",
    "print(tagged_sentences[0])\n",
    "print(\"Tagged sentences: \", len(tagged_sentences))\n",
    "print(\"Tagged words:\", len(nltk.corpus.treebank.tagged_words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features to use for classifier like 2-letter suffix  to indicate past-tense verbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word': 'a',\n",
       " 'is_first': False,\n",
       " 'is_last': False,\n",
       " 'is_capitalized': False,\n",
       " 'is_all_caps': False,\n",
       " 'is_all_lower': True,\n",
       " 'prefix-1': 'a',\n",
       " 'prefix-2': 'a',\n",
       " 'prefix-3': 'a',\n",
       " 'suffix-1': 'a',\n",
       " 'suffix-2': 'a',\n",
       " 'suffix-3': 'a',\n",
       " 'prev_word': 'was',\n",
       " 'next_word': 'brave',\n",
       " 'has_hyphen': False,\n",
       " 'is_numeric': False,\n",
       " 'capitals_inside': False}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def features(sentence, index):\n",
    "    \"\"\" sentence: [w1, w2, ...], index: the index of the word \"\"\"\n",
    "    return {\n",
    "        'word': sentence[index],\n",
    "        'is_first': index == 0,\n",
    "        'is_last': index == len(sentence) - 1,\n",
    "        'is_capitalized': sentence[index][0].upper() == sentence[index][0],\n",
    "        'is_all_caps': sentence[index].upper() == sentence[index],\n",
    "        'is_all_lower': sentence[index].lower() == sentence[index],\n",
    "        'prefix-1': sentence[index][0],\n",
    "        'prefix-2': sentence[index][:2],\n",
    "        'prefix-3': sentence[index][:3],\n",
    "        'suffix-1': sentence[index][-1],\n",
    "        'suffix-2': sentence[index][-2:],\n",
    "        'suffix-3': sentence[index][-3:],\n",
    "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
    "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n",
    "        'has_hyphen': '-' in sentence[index],\n",
    "        'is_numeric': sentence[index].isdigit(),\n",
    "        'capitals_inside': sentence[index][1:].lower() != sentence[index][1:]\n",
    "    }\n",
    " \n",
    "features(['Ram', 'was', 'a', 'brave' , 'warrior'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing tags from tagged corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Remove_tag(tagged_sentence):\n",
    "    return [w for w, t in tagged_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming corpus sentences to features for a single word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 3131\n",
      "Test size: 783\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset for training and testing\n",
    "splt = int(.80 * len(tagged_sentences))\n",
    "training_sentences = tagged_sentences[:splt]\n",
    "test_sentences = tagged_sentences[splt:]\n",
    "\n",
    "print(\"Training size:\",len(training_sentences))\n",
    "print(\"Test size:\",len(test_sentences))\n",
    " \n",
    "def transform_to_dataset(tagged_sentences):\n",
    "    X, y = [], [] \n",
    "    for tagged in tagged_sentences:\n",
    "        for index in range(len(tagged)):\n",
    "            X.append(features(Remove_tag(tagged), index))\n",
    "            y.append(tagged[index][1])\n",
    "    return X, y\n",
    " \n",
    "X, y = transform_to_dataset(training_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Classifier using Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed\n",
      "Accuracy: 0.894206297719447\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    " \n",
    "clf = Pipeline([\n",
    "    ('vectorizer', DictVectorizer(sparse=False)),\n",
    "    ('classifier', DecisionTreeClassifier(criterion='entropy'))\n",
    "])\n",
    " \n",
    "clf.fit(X[:10000], y[:10000])   # Use only the first 10K samples\n",
    " \n",
    "print('Training completed')\n",
    " \n",
    "X_test, y_test = transform_to_dataset(test_sentences)\n",
    " \n",
    "print(\"Accuracy:\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Own classifier to tag words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Let', 'CC'), ('us', 'PRP'), ('learn', 'NN'), ('NLP', 'NNP'), ('Tagging', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "def pos_tag(sentence):\n",
    "    tags = clf.predict([features(sentence, index) for index in range(len(sentence))])\n",
    "    return zip(sentence, tags)\n",
    "text = word_tokenize(\"Let us learn NLP Tagging.\")\n",
    "print(list(pos_tag(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
