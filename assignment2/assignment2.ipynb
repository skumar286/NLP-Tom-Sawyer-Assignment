{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781\n",
      "196\n"
     ]
    }
   ],
   "source": [
    "###Question 1 and 2\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.special import comb\n",
    "from collections import Counter\n",
    "import re\n",
    "import math\n",
    "import string\n",
    "import numpy as np\n",
    "with open(\"alice_wonderland.txt\") as file:\n",
    "    txt=file.read()\n",
    "\n",
    "corpus=[]\n",
    "#start and stop symbol added to tokenized sentence\n",
    "for line in sent_tokenize(txt):\n",
    "        lis = word_tokenize(line)\n",
    "        x=[word.lower() for word in lis if word.isalpha()]\n",
    "        y=['<s>']\n",
    "        y.extend(x)\n",
    "        y.append('</s>')\n",
    "        corpus.append(y)\n",
    "#print(r)\n",
    "with open('corpus.txt', 'w') as file:\n",
    "    for line in corpus:\n",
    "        for word in line:\n",
    "            file.write(word+' ')\n",
    "train_set,test_set = train_test_split(corpus,test_size=0.2,random_state=42)\n",
    "print(len(train_set))\n",
    "print(len(test_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram possible=  3111265\n",
      "Unigram present=  2495\n",
      "Bigrams possible=  99708381\n",
      "Bigrams present=  14122\n",
      "Trigrams possible=  251922681\n",
      "Trigrams present=  22447\n",
      "Quadgrams possible=  302149653\n",
      "Quadgrams present=  24583\n"
     ]
    }
   ],
   "source": [
    "###Question 3\n",
    "\n",
    "#calculating MLE for different gram\n",
    "def mle_gram(b,a):\n",
    "    if b == 0:\n",
    "        cnt=0\n",
    "        for val in a.values():\n",
    "            cnt+=val\n",
    "    d={}\n",
    "    for key in a.keys():\n",
    "        if a!=None:\n",
    "            temp=' '.join(key.split()[:-1])\n",
    "            cnt=b[temp]\n",
    "        d[key]=a[key]/float(cnt)\n",
    "    return d\n",
    "\n",
    "#calculating n-gram\n",
    "def cal_gram(corpus,n):\n",
    "    d=[]\n",
    "    for line in corpus:\n",
    "        l=[]\n",
    "        for w in line:\n",
    "            l.append(w)\n",
    "            if len(l) > n:\n",
    "                l.pop(0)\n",
    "            if len(l) == n:\n",
    "                gram=\" \".join(l)\n",
    "                d.append(gram)\n",
    "    counter = Counter(d)\n",
    "    return counter\n",
    "\n",
    "\n",
    "mle=[]\n",
    "\n",
    "for i in range(1,5):\n",
    "    mle.append(mle_gram(cal_gram(corpus,i-1),cal_gram(corpus,i)))\n",
    "#print(ml[0])\n",
    "\n",
    "#Print possible and present n-gram\n",
    "ng=[\"Unigram\",\"Bigrams\",\"Trigrams\",\"Quadgrams\"]   \n",
    "for i in range(1,5):\n",
    "    gram_present=len(cal_gram(corpus,i))\n",
    "    possb=int(comb(len(cal_gram(corpus,i)),2))\n",
    "    print(ng[i-1] ,\"possible= \",possb)\n",
    "    print(ng[i-1] ,\"present= \",gram_present)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here one of the deepest contempt\n",
      "either the locks were too large or the rest of the trees a little queer won t you didn t think of any that do alice said very politely if i only wish they would not give all else for two reasons\n",
      "i think that i ll take about this same thing tone why there could not and bit to dive in that i\n",
      "a a she of executioner s stay followed witness fire just have the sharply seemed things done think herself her too peeped eyes said proud one on there the you how\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-38.720860386181855"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Question 4(a)\n",
    "\n",
    "def Generator(mle, length_req):\n",
    "    sent = []\n",
    "    run = 10\n",
    "    remain = run\n",
    "\n",
    "    # n-Gram start character\n",
    "    end=''\n",
    "    while True:\n",
    "        #Sampling next word given last n-gram\n",
    "        if end == '':\n",
    "            keys = list(mle.keys())\n",
    "        else:\n",
    "            keys = [k for k in mle.keys() if (end + ' ' in k)]\n",
    "\n",
    "        #Probabilities of n-gram\n",
    "        prob_list = np.array([mle[k] for k in keys])\n",
    "        if len(keys) == 0:\n",
    "            first_Word ='</s>'\n",
    "\n",
    "        # Generating word with replacement\n",
    "        word = np.random.choice(keys, 1,replace=True, p=prob_list/np.sum(prob_list))\n",
    "        first_Word = word[0]\n",
    "        if ('<s>' in first_Word) and ('</s>' not in first_Word): \n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "    sent = first_Word.split()\n",
    "    end = ' '.join(sent[1:])\n",
    "    if len(sent) == 1:\n",
    "        end = ''\n",
    "    n = len(first_Word.split())\n",
    "    \n",
    "    #Iterating for remaining word\n",
    "    while(remain >= 0):\n",
    "        #Sampling next word given last n-gram\n",
    "        if end == '':\n",
    "            keys = list(mle.keys())\n",
    "        else:\n",
    "            keys = [k for k in mle.keys() if (end + ' ' in k)]\n",
    "        prob_list = np.array([mle[k] for k in keys])\n",
    "        prob_list = prob_list/np.sum(prob_list)\n",
    "\n",
    "        if len(keys) == 0:\n",
    "            word='</s>'\n",
    "        word = np.random.choice(keys, 1,replace=True, p=prob_list)\n",
    "        word=word[0]\n",
    "        if '<s>' in word:\n",
    "            pass\n",
    "        elif '</s>' in word:\n",
    "            remain -= 1\n",
    "            if len(sent)-1 >= length_req:\n",
    "                return ' '.join(sent[1:])\n",
    "        else:\n",
    "            sent.append(word.split()[-1])\n",
    "            remain = run\n",
    "            end = ' '.join(word.split()[1:])\n",
    "    return ' '.join(sent[1:])\n",
    "\n",
    "\n",
    "#Probability of sentence in log space\n",
    "def Probability(sent, mle):\n",
    "    n_value = len(list(mle.keys())[0].split(' '))\n",
    "    words = (\"<s> \"+sent+\" </s>\").split(\" \")\n",
    "    prob = 0\n",
    "    for i in range(n_value - 1,len(words)):\n",
    "        word = words[i]\n",
    "        for j in range(i-1,i-(n_value),-1):\n",
    "           word = words[j]+\" \"+word\n",
    "        try:\n",
    "           prob += math.log(mle[word])\n",
    "        except KeyError:\n",
    "            return -1e-10 \n",
    "    return (prob)\n",
    "\n",
    "\n",
    "k = 10 \n",
    "N=4\n",
    "for i in range(N, 0, -1):\n",
    "    print (Generator(mle[i-1], k))\n",
    "    \n",
    "######Question 4(b)\n",
    "Probability(\"presently the rabbit came near her she began in a great hurry\", mle[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram with add-1 smoothing: 24\n",
      "Bigram without add-1 smoothing 72\n",
      "Bigram with add-1 smoothing: 39\n",
      "Bigram without add-1 smoothing 116\n"
     ]
    }
   ],
   "source": [
    "###Question 5\n",
    "class Add1Smooth(object):\n",
    "    def __init__(self, dicB, dicS):\n",
    "        self.dicB = dicB\n",
    "        self.dicS = dicS\n",
    "\n",
    "    def UpdatedCount(self, bs):\n",
    "        try:\n",
    "            num = self.dicB[bs] + 1\n",
    "        except KeyError:\n",
    "            num = 1\n",
    "            \n",
    "        cnt = 0\n",
    "        for val in self.dicB.values():\n",
    "            cnt += val\n",
    "        den =cnt + len(self.dicB)\n",
    "\n",
    "        # returns (C+1)*N/(N+V) that is new count\n",
    "        return int((len(self.dicB) * num)/int(den))\n",
    "\n",
    "obj = Add1Smooth(cal_gram(corpus,2), cal_gram(corpus,1))\n",
    "#print(cal_gram(2))\n",
    "##First Example\n",
    "print (\"Bigram with add-1 smoothing:\", obj.UpdatedCount(\"the queen\"))\n",
    "print (\"Bigram without add-1 smoothing\", cal_gram(corpus,2)[\"the queen\"])\n",
    "\n",
    "##Second Example\n",
    "print (\"Bigram with add-1 smoothing:\", obj.UpdatedCount(\"said alice\"))\n",
    "print (\"Bigram without add-1 smoothing\", cal_gram(corpus,2)[\"said alice\"])\n",
    "\n",
    "\n",
    "### Drastic change in sentence occurs because only 1% bigram present in corpus - \n",
    "## and other 99% bigram steal the probability mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count without and with Good Turing {0: 0.003372716540625392, 1: 0.33266571292322367, 2: 1.1852064220183487, 3: 1.7706821480406385, 4: 3.377049180327869, 5: 4.048543689320389, 6: 5.489208633093525, 7: 5.944954128440367, 8: 6.777777777777778, 9: 5.573770491803279}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Count Difference')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "####Question 6\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def freq_of_freq(dic):\n",
    "    f = {}\n",
    "    for key in dic.keys():\n",
    "        freq = dic[key]\n",
    "        try:\n",
    "            f[freq] += 1\n",
    "\n",
    "        except KeyError:\n",
    "            f[freq] = 1\n",
    "    f[0]=0\n",
    "    return f\n",
    "class GoodTuring(object):\n",
    "    def __init__(self, dicB, dicC):\n",
    "        self.dicB = dicB\n",
    "        self.dicC = dicC\n",
    "        self.f = {}\n",
    "        self.newCounts = {}\n",
    "\n",
    "    def Prob(self, bigram):\n",
    "        bigram_cnt = 0\n",
    "        for key in f.keys():\n",
    "            bigram_cnt += dic[key]\n",
    "\n",
    "        if bigram not in self.dicB.keys():\n",
    "            return (self.f[0]/bigram_cnt)\n",
    "        return self.dicB[bigram]/self.dicC[bigram.split()[0]]\n",
    "\n",
    "\n",
    "    def NewCounts(self, counts=10):\n",
    "        dicB = self.dicB\n",
    "        dicC = self.dicC\n",
    "        self.f = freq_of_freq(dicB)\n",
    "        val_cnts = 0\n",
    "        for key in dicB.keys():\n",
    "            val_cnts += dicB[key]\n",
    "\n",
    "        poss_bigram = comb(len(dicC.keys()), 2)\n",
    "        bigram_present=len(dicC.keys())\n",
    "        bigram_unpresnt = poss_bigram - bigram_present\n",
    "        self.f[0] = bigram_unpresnt\n",
    "        lis = []\n",
    "\n",
    "        # calculate the new freq_of_freq\n",
    "        for i in range(counts):\n",
    "            try:\n",
    "                self.newCounts[i] = self.f[i+1]*(i+1)/float(self.f[i])\n",
    "            except ZeroDivisionError:\n",
    "                lis.append(i)\n",
    "                continue \n",
    "\n",
    "        # estimate lis\n",
    "        def func(x, a, k): # f(x) = a*exp(-kx) == Nc\n",
    "            return a*(np.exp(-k*x))\n",
    "        popt = curve_fit(func, list(self.f.keys()),list(self.f.values()))\n",
    "        for i in lis:\n",
    "            self.newCounts[i] = self.f[i+1]*(i+1)\\\n",
    "            /func(i, popt[0], popt[1])\n",
    "\n",
    "        return self.newCounts\n",
    "\n",
    "obj = GoodTuring(cal_gram(corpus,2), cal_gram(corpus,1))\n",
    "val = obj.NewCounts(counts=10)\n",
    "print ('Count without and with Good Turing',val)\n",
    "\n",
    "x = [keys for keys in val.keys()]\n",
    "y = [keys - val[keys] for keys in val.keys()]\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel(\"Init_count\")\n",
    "plt.ylabel(\"Count Difference\")\n",
    "\n",
    "\n",
    "#### Average d value is 0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
